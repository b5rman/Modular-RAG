{
  "name": "RAG Retrieval Sub-Workflow v1.0.8c",
  "nodes": [
    {
      "parameters": {
        "content": "# State-of-the-Art RAG Agent (With Dynamic Hybrid Search & Context Expansion)",
        "height": 648,
        "width": 1052,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        864,
        0
      ],
      "id": "ebce0334-9a7b-4a38-9516-377b1a8793ec",
      "name": "Sticky Note6"
    },
    {
      "parameters": {
        "content": "",
        "height": 648,
        "width": 840,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        0,
        0
      ],
      "id": "d649604f-d4ea-4637-b22c-9505060cb712",
      "name": "Sticky Note18"
    },
    {
      "parameters": {
        "contextWindowLength": 10
      },
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "typeVersion": 1.3,
      "position": [
        1264,
        448
      ],
      "id": "74044404-c007-499e-8011-428e2bd1827b",
      "name": "Supabase Short-Term Memory",
      "credentials": {
        "postgres": {
          "id": "tRlTzpjOmrCVSNLF",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "content": "## v2.3.3\nThis it the agentic inference workflow for both our SOTA RAG System and RAG At Scale System\n\nSOTA RAG Setup instructions here:\nhttps://community.theaiautomators.com/c/automation-templates/state-of-the-art-n8n-rag-agent\n\nRAG at Scale Setup instructions here:\nhttps://community.theaiautomators.com/c/automation-templates/rag-at-scale-system",
        "height": 244,
        "width": 580,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        160,
        368
      ],
      "id": "af3730c0-82ec-4486-813c-aed558653052",
      "name": "Sticky Note21"
    },
    {
      "parameters": {
        "content": "# State-of-the-Art RAG Agent (With Long Term Memory)",
        "height": 648,
        "width": 2076,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        3440,
        0
      ],
      "id": "2d3054a0-5fcc-4b37-94f6-0498795b3c08",
      "name": "Sticky Note20",
      "disabled": true
    },
    {
      "parameters": {
        "name": "Query_Knowledge_Graph",
        "description": "Call this to query data from our knowledge graph",
        "workflowId": {
          "__rl": true,
          "value": "A4BVrX5qYlJ7HUMI",
          "mode": "list",
          "cachedResultName": "TheAIAutomators.com - RAG Masterclass - Lesson 9 - SOTA - v2.0 Dev 0.3"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "query": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('query', ``, 'string') }}",
            "session_id": "={{ $json.sessionId }}",
            "type": "graph"
          },
          "matchingColumns": [],
          "schema": [
            {
              "id": "query",
              "displayName": "query",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string"
            },
            {
              "id": "type",
              "displayName": "type",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string"
            },
            {
              "id": "session_id",
              "displayName": "session_id",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string"
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2.1,
      "position": [
        4640,
        480
      ],
      "id": "05e86177-e484-40b0-ba56-48a218cc0ebb",
      "name": "Query Knowledge Graph1",
      "retryOnFail": true,
      "maxTries": 5,
      "waitBetweenTries": 5000,
      "disabled": true
    },
    {
      "parameters": {
        "contextWindowLength": 10
      },
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "typeVersion": 1.3,
      "position": [
        3984,
        480
      ],
      "id": "4f3b6011-2766-467d-a110-8ec59d4cfaa5",
      "name": "Supabase Short-Term Memory2",
      "credentials": {
        "postgres": {
          "id": "tRlTzpjOmrCVSNLF",
          "name": "Postgres account"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.getzep.com/api/v2/graph/search",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"user_id\": \"{{ $json.user_id }}\",\n  \"query\": {{ JSON.stringify($('When chat message received').item.json.chatInput) }},\n  \"scope\": \"edges\",\n  \"limit\": 5,\n  \"search_filters\": {\n    \"min_relevance\": 0.7\n  }\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3872,
        224
      ],
      "id": "b1f0dea0-94b3-427c-b58f-ba4a90b2af98",
      "name": "Get Long Term Memories",
      "disabled": true
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.4,
      "position": [
        4784,
        288
      ],
      "id": "9a0b8f14-e0e2-4886-a079-5089fd1b2613",
      "name": "Respond to Webhook",
      "disabled": true
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "c2e95998-ad5f-4676-b307-b91f5c4adaad",
              "name": "user_id",
              "value": "user1234",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        3616,
        224
      ],
      "id": "0a4e43cf-a1fd-4da1-ab61-5b5bba580140",
      "name": "user_id",
      "disabled": true
    },
    {
      "parameters": {
        "content": "Note: This template uses n8n chat and by default, this long term memory is shared across all chat sessions. To maintain separate long term memories for different users, check out our community post here, as there are multiple approaches for this depending on how you're deploying the agent. ",
        "height": 192,
        "width": 256,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3536,
        400
      ],
      "typeVersion": 1,
      "id": "48ec6787-0e2e-41eb-85e0-c51347f39238",
      "name": "Sticky Note25",
      "disabled": true
    },
    {
      "parameters": {
        "content": "## TODO\n### Add User ID here",
        "height": 232,
        "width": 232
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        3552,
        144
      ],
      "id": "132dde66-6ee7-4c19-b38c-8490de2fda27",
      "name": "Sticky Note26",
      "disabled": true
    },
    {
      "parameters": {
        "descriptionType": "manual",
        "toolDescription": "Execute a SQL query on the tabular_document_rows table.\n\nInstructions:\n\nYou will always be querying based on a specific id.\n\nEach row in the table contains a row_data field (of type jsonb) that holds the data for that row, with keys matching the file schema defined in the record_manager table.\n\nThe record_manager_id is the id field from the record_manager table. Always filter based on this specific id when querying the tabular_document_rows table.\n\nWhen writing your SELECT clause, extract values from the row_data JSON using the ->> operator and cast them as needed (e.g., to numeric for calculations).\n\nItems within your SELECT needs to use the data within row_data field.\n\nExample query: Find maximum value for a field (e.g. \"profit\")\n\nSELECT MAX((row_data->>'profit')::numeric) AS max_profit\nFROM tabular_document_rows\nWHERE file_id = '123';\n\nExample query: Group and aggregate (e.g. total revenue by country)\n\nSELECT row_data->>'country' AS country,\n       SUM((row_data->>'revenue')::numeric) AS total_revenue\nFROM tabular_document_rows\nWHERE record_manager_id = '123'\nGROUP BY row_data->>'country';\n\nExample query: Group and aggregate (e.g. total revenue by country)\nSELECT row_data->>'salesperson' AS salesperson,\n       SUM((row_data->>'profit')::numeric) AS total_profit\nFROM tabular_document_rows\nWHERE record_manager_id = '123'\nGROUP BY row_data->>'salesperson';",
        "operation": "executeQuery",
        "query": "{{ $fromAI('sql_query') }}",
        "options": {}
      },
      "type": "n8n-nodes-base.postgresTool",
      "typeVersion": 2.5,
      "position": [
        4304,
        480
      ],
      "id": "78275a46-e110-44be-ad46-91c22e07a4f7",
      "name": "Query Tabular Rows1",
      "credentials": {
        "postgres": {
          "id": "tRlTzpjOmrCVSNLF",
          "name": "Postgres account"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "descriptionType": "manual",
        "toolDescription": "Use this tool to fetch all available documents from the record_manager, this will include the table schema and the id",
        "operation": "select",
        "schema": {
          "__rl": true,
          "mode": "list",
          "value": "public"
        },
        "table": {
          "__rl": true,
          "value": "record_manager_v2",
          "mode": "list",
          "cachedResultName": "record_manager_v2"
        },
        "returnAll": true,
        "where": {
          "values": [
            {
              "column": "data_type",
              "value": "tabular"
            }
          ]
        },
        "options": {
          "outputColumns": [
            "id",
            "document_title",
            "schema"
          ]
        }
      },
      "type": "n8n-nodes-base.postgresTool",
      "typeVersion": 2.5,
      "position": [
        4144,
        480
      ],
      "id": "c9fda40f-ad60-4fb8-b921-31d3f825dd96",
      "name": "Get datasets from record_manager1",
      "credentials": {
        "postgres": {
          "id": "tRlTzpjOmrCVSNLF",
          "name": "Postgres account"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.getzep.com/api/v2/users",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\"user_id\":\"user1234\"}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        5248,
        336
      ],
      "id": "23c4b715-78ae-442c-b9b0-e9c5fb230400",
      "name": "Create Zep User",
      "disabled": true
    },
    {
      "parameters": {
        "content": "## TODO\n### Run this node once to manually create a Zep user",
        "height": 312,
        "width": 232
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        5184,
        192
      ],
      "id": "ead6a292-ded6-47b5-bc96-8566fba90733",
      "name": "Sticky Note27",
      "disabled": true
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "jfvPAjwlf1jVaW3Y",
          "mode": "list",
          "cachedResultName": "Zep - Update Long Term Memories - BLUEPRINT"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "session_id": "={{ $('When chat message received').item.json.sessionId }}",
            "user_id": "={{ $('user_id').item.json.user_id }}",
            "message_content": "={{ $('When chat message received').item.json.chatInput }}"
          },
          "matchingColumns": [],
          "schema": [
            {
              "id": "session_id",
              "displayName": "session_id",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string"
            },
            {
              "id": "user_id",
              "displayName": "user_id",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string"
            },
            {
              "id": "message_content",
              "displayName": "message_content",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string"
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": true
        },
        "options": {
          "waitForSubWorkflow": false
        }
      },
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.2,
      "position": [
        4784,
        80
      ],
      "id": "c00f6662-379f-4ae9-a1d8-32fb2bcc583a",
      "name": "Execute workflow - Save Zep long term memories",
      "disabled": true
    },
    {
      "parameters": {
        "public": true,
        "authentication": "n8nUserAuth",
        "initialMessages": "Hi there! ðŸ‘‹\n",
        "availableInChat": true,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.3,
      "position": [
        352,
        176
      ],
      "id": "b0524417-3c28-4ae4-97cf-1fad8ea10106",
      "name": "When chat message received",
      "webhookId": "5e442826-4547-4647-8d24-1641210f2a8e"
    },
    {
      "parameters": {
        "name": "Query_Knowledge_Graph",
        "description": "Call this to query data from our knowledge graph",
        "workflowId": {
          "__rl": true,
          "value": "suQZAl0QM15VyY3R",
          "mode": "list",
          "cachedResultUrl": "/workflow/suQZAl0QM15VyY3R",
          "cachedResultName": "TheAIAutomators.com - SOTA RAG AGENT - v2.3 Blueprint"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "query": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('query', ``, 'string') }}",
            "session_id": "={{ $json.sessionId }}",
            "type": "graph"
          },
          "matchingColumns": [],
          "schema": [
            {
              "id": "query",
              "displayName": "query",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string"
            },
            {
              "id": "type",
              "displayName": "type",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string"
            },
            {
              "id": "session_id",
              "displayName": "session_id",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string"
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2.1,
      "position": [
        2864,
        448
      ],
      "id": "1a986fa5-df98-4310-8ba5-0d76d4d7d80b",
      "name": "Query Knowledge Graph2",
      "retryOnFail": true,
      "maxTries": 5,
      "waitBetweenTries": 5000,
      "disabled": true
    },
    {
      "parameters": {
        "contextWindowLength": 10
      },
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "typeVersion": 1.3,
      "position": [
        2192,
        448
      ],
      "id": "035167b2-f0fb-4990-a5f3-e748ab6a52db",
      "name": "Supabase Short-Term Memory3",
      "credentials": {
        "postgres": {
          "id": "tRlTzpjOmrCVSNLF",
          "name": "Postgres account"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "descriptionType": "manual",
        "toolDescription": "Execute a SQL query on the tabular_document_rows table. \n\nInstructions:\n\nYou will always be querying based on a specific id.\n\nEach row in the table contains a row_data field (of type jsonb) that holds the data for that row, with keys matching the file schema defined in the record_manager table.\n\nThe record_manager_id is the id field from the record_manager table. Always filter based on this specific id when querying the tabular_document_rows table.\n\nWhen writing your SELECT clause, extract values from the row_data JSON using the ->> operator and cast them as needed (e.g., to numeric for calculations).\n\nWhen applying WHERE clauses, you should run SELECT DISTINCT queries (LIMIT 100) on the relevant fields first to understand the valid options. This applies even if the user provides a specific valueâ€”you must verify that the value exists in the data before using it.\n\nDo NOT run SELECT DISTINCT queries for ID columns.\n\nItems within your SELECT needs to use the data within row_data field.\n\nExample query: Find maximum value for a field (e.g. \"profit\")\n\nSELECT MAX((row_data->>'profit')::numeric) AS max_profit\nFROM tabular_document_rows\nWHERE file_id = '123';\n\nExample query: Group and aggregate (e.g. total revenue by country)\n\nSELECT row_data->>'country' AS country,\n       SUM((row_data->>'revenue')::numeric) AS total_revenue\nFROM tabular_document_rows\nWHERE record_manager_id = '123'\nGROUP BY row_data->>'country';\n\nExample query: Group and aggregate (e.g. total revenue by country)\nSELECT row_data->>'salesperson' AS salesperson,\n       SUM((row_data->>'profit')::numeric) AS total_profit\nFROM tabular_document_rows\nWHERE record_manager_id = '123'\nGROUP BY row_data->>'salesperson';",
        "operation": "executeQuery",
        "query": "{{ $fromAI('sql_query') }}",
        "options": {}
      },
      "type": "n8n-nodes-base.postgresTool",
      "typeVersion": 2.5,
      "position": [
        2512,
        448
      ],
      "id": "0e89261f-22a4-49cb-abe2-ed9310e79b51",
      "name": "Query Tabular Rows2",
      "credentials": {
        "postgres": {
          "id": "tRlTzpjOmrCVSNLF",
          "name": "Postgres account"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "descriptionType": "manual",
        "toolDescription": "Use this tool to fetch all available documents from the record_manager, this will include the table schema and the id",
        "operation": "select",
        "schema": {
          "__rl": true,
          "mode": "list",
          "value": "public"
        },
        "table": {
          "__rl": true,
          "value": "record_manager_v2",
          "mode": "list",
          "cachedResultName": "record_manager_v2"
        },
        "returnAll": true,
        "where": {
          "values": [
            {
              "column": "data_type",
              "value": "tabular"
            }
          ]
        },
        "options": {
          "outputColumns": [
            "id",
            "document_title",
            "schema"
          ]
        }
      },
      "type": "n8n-nodes-base.postgresTool",
      "typeVersion": 2.5,
      "position": [
        2352,
        448
      ],
      "id": "f238fefe-8653-45e9-9c23-8c971aa60768",
      "name": "Get datasets from record_manager2",
      "credentials": {
        "postgres": {
          "id": "tRlTzpjOmrCVSNLF",
          "name": "Postgres account"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "content": "# State-of-the-Art RAG Agent (With GraphRAG + NLQ)",
        "height": 648,
        "width": 1468,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        1936,
        0
      ],
      "id": "84355434-8cf9-45ee-bfa1-525aed03f5ae",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "content": "## TODO\n### Connect the Chat Trigger to your Agent of Choice",
        "height": 256,
        "width": 576
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        160,
        80
      ],
      "id": "083bf93c-97cd-4393-bb5e-07f70eee820f",
      "name": "Sticky Note29"
    },
    {
      "parameters": {
        "description": "=Call this tool to query data from our knowledgebase using hybrid search (vector, lexical, ilike and fuzzy)\n\nYou can set different weights of this hybrid search depending on the type of query.\n\ndense_weight float DEFAULT 0.5,\nsparse_weight float DEFAULT 0.5,\nilike_weight float DEFAULT 0\nfuzzy_weight float DEFAULT 0\nfuzzy_threshold float DEFAULT 0.8\n\nFor semantic natural lanauge queries you can prioritise dense embeddings, \nFor technical terms and more traditional search you can priorize sparse lexical search\nFor exact matches for codes and IDs you can prioritze ilike wildcard matching\nFor typos that aren't picked up by semantic search, you can prioritize fuzzy matching\n\nIf looking for matches via ilike or fuzzy matches, the query should be extremely focused and short, as otherwise it will likely return zero results. (e.g. exact ID or code)\n\nAs pattern matching and fuzzy matching can add latency, I recommend defaulting this to zero unless you want to actually use it.\n\nTotal of the 4 weights much equal 1\n\nFuzzy Threshold adds significant latency should should be as high as possible - Default to 0.8",
        "workflowId": {
          "__rl": true,
          "value": "Bgl5d3deLQufGLff",
          "mode": "list",
          "cachedResultUrl": "/workflow/Bgl5d3deLQufGLff",
          "cachedResultName": "SOTA RAG Retrieval Sub-Workflow"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "query": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('query', ``, 'string') }}",
            "session_id": "={{ $json.sessionId }}",
            "sparse_weight": "={{ $fromAI('sparse_weight', ``, 'number', 0.5) }}",
            "dense_weight": "={{ $fromAI('dense_weight', ``, 'number', 0.5) }}",
            "fuzzy_threshold": "={{ $fromAI('fuzzy_threshold', `this is the word similarity threshold in postgres - lower means more candidates however the call may time out`, 'number', 0.8) }}",
            "fuzzy_weight": "={{ $fromAI('fuzzy_weight', ``, 'number', 0) }}",
            "ilike_weight": "={{ $fromAI('ilike_weight', ``, 'number', 0) }}",
            "type": "hybrid"
          },
          "matchingColumns": [],
          "schema": [
            {
              "id": "query",
              "displayName": "query",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            },
            {
              "id": "type",
              "displayName": "type",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            },
            {
              "id": "session_id",
              "displayName": "session_id",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            },
            {
              "id": "dense_weight",
              "displayName": "dense_weight",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "number",
              "removed": false
            },
            {
              "id": "sparse_weight",
              "displayName": "sparse_weight",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "number",
              "removed": false
            },
            {
              "id": "ilike_weight",
              "displayName": "ilike_weight",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "number",
              "removed": false
            },
            {
              "id": "fuzzy_weight",
              "displayName": "fuzzy_weight",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "number",
              "removed": false
            },
            {
              "id": "fuzzy_threshold",
              "displayName": "fuzzy_threshold",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "number",
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2.2,
      "position": [
        1424,
        448
      ],
      "id": "c793ede6-b98d-4166-ba20-c7bc5a839b2c",
      "name": "Dynamic Hybrid Search"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-5-20250929",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4.5"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        2032,
        448
      ],
      "id": "ce7123fa-2927-4892-a3c2-ec7228769394",
      "name": "Anthropic Chat Model1",
      "disabled": true
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-5-20250929",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4.5"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        3824,
        480
      ],
      "id": "c74fd6fd-21aa-4c0c-9742-b6663cd796c7",
      "name": "Anthropic Chat Model2",
      "disabled": true
    },
    {
      "parameters": {
        "description": "=Call this tool to query data from our knowledgebase using hybrid search (vector, lexical, ilike and fuzzy)\n\nYou can set different weights of this hybrid search depending on the type of query.\n\ndense_weight float DEFAULT 0.5,\nsparse_weight float DEFAULT 0.5,\nilike_weight float DEFAULT 0\nfuzzy_weight float DEFAULT 0\nfuzzy_threshold float DEFAULT 0.8\n\nFor semantic natural lanauge queries you can prioritise dense embeddings, \nFor technical terms and more traditional search you can priorize sparse lexical search\nFor exact matches for codes and IDs you can prioritze ilike wildcard matching\nFor typos that aren't picked up by semantic search, you can prioritize fuzzy matching\n\nIf looking for matches via ilike or fuzzy matches, the query should be extremely focused and short, as otherwise it will likely return zero results. (e.g. exact ID or code)\n\nAs pattern matching and fuzzy matching can add latency, I recommend defaulting this to zero unless you want to actually use it.\n\nTotal of the 4 weights much equal 1\n\nFuzzy Threshold adds significant latency should should be as high as possible - Default to 0.8",
        "workflowId": {
          "__rl": true,
          "value": "suQZAl0QM15VyY3R",
          "mode": "list",
          "cachedResultUrl": "/workflow/suQZAl0QM15VyY3R",
          "cachedResultName": "TheAIAutomators.com - SOTA RAG AGENT - v2.3 Blueprint"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "query": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('query', ``, 'string') }}",
            "session_id": "={{ $json.sessionId }}",
            "sparse_weight": "={{ $fromAI('sparse_weight', ``, 'number', 0.5) }}",
            "dense_weight": "={{ $fromAI('dense_weight', ``, 'number', 0.5) }}",
            "fuzzy_threshold": "={{ $fromAI('fuzzy_threshold', `this is the word similarity threshold in postgres - lower means more candidates however the call may time out`, 'number', 0.8) }}",
            "fuzzy_weight": "={{ $fromAI('fuzzy_weight', ``, 'number', 0) }}",
            "ilike_weight": "={{ $fromAI('ilike_weight', ``, 'number', 0) }}",
            "type": "hybrid"
          },
          "matchingColumns": [],
          "schema": [
            {
              "id": "query",
              "displayName": "query",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            },
            {
              "id": "type",
              "displayName": "type",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            },
            {
              "id": "session_id",
              "displayName": "session_id",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            },
            {
              "id": "dense_weight",
              "displayName": "dense_weight",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "number",
              "removed": false
            },
            {
              "id": "sparse_weight",
              "displayName": "sparse_weight",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "number",
              "removed": false
            },
            {
              "id": "ilike_weight",
              "displayName": "ilike_weight",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "number",
              "removed": false
            },
            {
              "id": "fuzzy_weight",
              "displayName": "fuzzy_weight",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "number",
              "removed": false
            },
            {
              "id": "fuzzy_threshold",
              "displayName": "fuzzy_threshold",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "number",
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2.2,
      "position": [
        2688,
        448
      ],
      "id": "5c38a44e-a3a1-45cc-9c89-8f8f68d21fce",
      "name": "Dynamic Hybrid Search1",
      "disabled": true
    },
    {
      "parameters": {
        "description": "=Call this tool to query data from our knowledgebase using hybrid search (vector, lexical, ilike and fuzzy)\n\nYou can set different weights of this hybrid search depending on the type of query.\n\ndense_weight float DEFAULT 0.5,\nsparse_weight float DEFAULT 0.5,\nilike_weight float DEFAULT 0\nfuzzy_weight float DEFAULT 0\nfuzzy_threshold float DEFAULT 0.8\n\nFor semantic natural lanauge queries you can prioritise dense embeddings, \nFor technical terms and more traditional search you can priorize sparse lexical search\nFor exact matches for codes and IDs you can prioritze ilike wildcard matching\nFor typos that aren't picked up by semantic search, you can prioritize fuzzy matching\n\nIf looking for matches via ilike or fuzzy matches, the query should be extremely focused and short, as otherwise it will likely return zero results. (e.g. exact ID or code)\n\nAs pattern matching and fuzzy matching can add latency, I recommend defaulting this to zero unless you want to actually use it.\n\nTotal of the 4 weights much equal 1\n\nFuzzy Threshold adds significant latency should should be as high as possible - Default to 0.8",
        "workflowId": {
          "__rl": true,
          "value": "BBep2uTA4ZltoqZF",
          "mode": "list",
          "cachedResultName": "TheAIAutomators.com - SOTA RAG AGENT - v2.2 Active"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "query": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('query', ``, 'string') }}",
            "session_id": "={{ $json.sessionId }}",
            "sparse_weight": "={{ $fromAI('sparse_weight', ``, 'number', 0.5) }}",
            "dense_weight": "={{ $fromAI('dense_weight', ``, 'number', 0.5) }}",
            "fuzzy_threshold": "={{ $fromAI('fuzzy_threshold', `this is the word similarity threshold in postgres - lower means more candidates however the call may time out`, 'number', 0.8) }}",
            "fuzzy_weight": "={{ $fromAI('fuzzy_weight', ``, 'number', 0) }}",
            "ilike_weight": "={{ $fromAI('ilike_weight', ``, 'number', 0) }}",
            "type": "hybrid"
          },
          "matchingColumns": [],
          "schema": [
            {
              "id": "query",
              "displayName": "query",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            },
            {
              "id": "type",
              "displayName": "type",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            },
            {
              "id": "session_id",
              "displayName": "session_id",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            },
            {
              "id": "dense_weight",
              "displayName": "dense_weight",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "number",
              "removed": false
            },
            {
              "id": "sparse_weight",
              "displayName": "sparse_weight",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "number",
              "removed": false
            },
            {
              "id": "ilike_weight",
              "displayName": "ilike_weight",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "number",
              "removed": false
            },
            {
              "id": "fuzzy_weight",
              "displayName": "fuzzy_weight",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "number",
              "removed": false
            },
            {
              "id": "fuzzy_threshold",
              "displayName": "fuzzy_threshold",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "number",
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2.2,
      "position": [
        4480,
        480
      ],
      "id": "49a970a2-b720-4fad-baba-14ba0c7c7fdd",
      "name": "Dynamic Hybrid Search2",
      "disabled": true
    },
    {
      "parameters": {
        "operation": "getAll",
        "tableId": "record_manager_v2",
        "limit": 1,
        "filters": {
          "conditions": [
            {
              "keyName": "doc_id",
              "condition": "eq",
              "keyValue": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('conditions0_Field_Value', ``, 'string') }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.supabaseTool",
      "typeVersion": 1,
      "position": [
        1584,
        448
      ],
      "id": "cbc62d85-1c51-4178-9bba-f327af8b851e",
      "name": "Fetch Document Hierarchy",
      "credentials": {
        "supabaseApi": {
          "id": "JXvQLWfqIjdcMyqm",
          "name": "Supabase B5rman"
        }
      }
    },
    {
      "parameters": {
        "toolDescription": "Based on the most promising chunks retrieved from the knowledgebase, use this tool to expand out the context by fetching neighbouring chunks, parent chunks etc\n\nThe body of this call must be in this format and the values you need are in the chunk metadata. You can retrieve chunks from one or multiple documents if you like\n[\n    {\n      doc_id: \"doc-id-12345-abcde\",\n      chunk_ranges: [[0, 5]]\n    },\n    {\n      doc_id: \"another-doc-id-12345\",\n      chunk_ranges: [[10, 15], [20, 25]]\n    }\n  ]\n",
        "method": "POST",
        "url": "https://mgistrmwhxccyuchokbh.supabase.co/functions/v1/context-expansion",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "supabaseApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('JSON', ``, 'json') }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequestTool",
      "typeVersion": 4.2,
      "position": [
        1760,
        448
      ],
      "id": "57fe1287-5f31-4ef9-b326-2dc6dae98190",
      "name": "Context Expansion",
      "credentials": {
        "supabaseApi": {
          "id": "JXvQLWfqIjdcMyqm",
          "name": "Supabase B5rman"
        }
      }
    },
    {
      "parameters": {
        "operation": "getAll",
        "tableId": "record_manager_v2",
        "limit": 1,
        "filters": {
          "conditions": [
            {
              "keyName": "doc_id",
              "condition": "eq",
              "keyValue": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('conditions0_Field_Value', ``, 'string') }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.supabaseTool",
      "typeVersion": 1,
      "position": [
        3024,
        448
      ],
      "id": "8586b512-1f36-4c51-a609-91b50d9133e7",
      "name": "Fetch Document Hierarchy1",
      "credentials": {
        "supabaseApi": {
          "id": "JXvQLWfqIjdcMyqm",
          "name": "Supabase B5rman"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "toolDescription": "Based on the most promising chunks retrieved from the knowledgebase, use this tool to expand out the context by fetching neighbouring chunks, parent chunks etc\n\nThe body of this call must be in this format and the values you need are in the chunk metadata. You can retrieve chunks from one or multiple documents if you like\n[\n    {\n      doc_id: \"doc-id-12345-abcde\",\n      chunk_ranges: [[0, 5]]\n    },\n    {\n      doc_id: \"another-doc-id-12345\",\n      chunk_ranges: [[10, 15], [20, 25]]\n    }\n  ]\n",
        "method": "POST",
        "url": "https://iwcionhpeltdhfrtimtp.supabase.co/functions/v1/context-expansion",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "supabaseApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('JSON', ``, 'json') }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequestTool",
      "typeVersion": 4.2,
      "position": [
        3200,
        448
      ],
      "id": "d5cd206f-cf89-4838-a997-784088dbb27a",
      "name": "Context Expansion1",
      "disabled": true
    },
    {
      "parameters": {
        "operation": "getAll",
        "tableId": "record_manager_v2",
        "limit": 1,
        "filters": {
          "conditions": [
            {
              "keyName": "doc_id",
              "condition": "eq",
              "keyValue": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('conditions0_Field_Value', ``, 'string') }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.supabaseTool",
      "typeVersion": 1,
      "position": [
        4800,
        480
      ],
      "id": "76bd219e-abb8-4edd-ad1c-da731cc3bd8e",
      "name": "Fetch Document Hierarchy2",
      "credentials": {
        "supabaseApi": {
          "id": "JXvQLWfqIjdcMyqm",
          "name": "Supabase B5rman"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "toolDescription": "Based on the most promising chunks retrieved from the knowledgebase, use this tool to expand out the context by fetching neighbouring chunks, parent chunks etc\n\nThe body of this call must be in this format and the values you need are in the chunk metadata. You can retrieve chunks from one or multiple documents if you like\n[\n    {\n      doc_id: \"doc-id-12345-abcde\",\n      chunk_ranges: [[0, 5]]\n    },\n    {\n      doc_id: \"another-doc-id-12345\",\n      chunk_ranges: [[10, 15], [20, 25]]\n    }\n  ]\n",
        "method": "POST",
        "url": "https://iwcionhpeltdhfrtimtp.supabase.co/functions/v1/context-expansion",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "supabaseApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('JSON', ``, 'json') }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequestTool",
      "typeVersion": 4.2,
      "position": [
        4976,
        480
      ],
      "id": "33a485c2-d8de-415f-8ede-95c5a94dda60",
      "name": "Context Expansion2",
      "disabled": true
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $('When chat message received').item.json.chatInput }}",
        "options": {
          "systemMessage": "=# Role\n\nYou are an AI assistant responding to a user's query based on the information avaialble in the knowledgebase.\n\n# Goal\n\nYou are tasked with creating and executing a retrieval strategy to best answer the users question.\n\nThe output should be a well-reserached response to the users query based on the output from these tools and to follow the Operating Procedures and Response Rules as set about below.\n\nYou must consider both the conversation history and the current query.\n\nYour goal is to provide a fully grounded, accurate answer based on the output from these tools ONLY.\n\n# Standard Operating Procedure\n\n1. Based on your retrieval strategy, pass relevant query(s) to the dynamic hybrid search to narrow the search and retrieve candidate chunks\n2. Based on the most relevant chunk(s); Trigger the Fetch Document Hierarchy Tool to load the source Documents Structure\n3. Based on this document structure (which includes chunk ranges) along with any relevant child_ranges and parent_ranges from the retrieved chunks, trigger the Context Expansion tool to expand your insight into the document.\n\nOnce you've collected enough information, then answer the question, based on the info in context.\n\n# Response Rules\n\n- Ideal target format and length: Multiple Paragraphs\n- Use markdown formatting with appropriate section headings\n- Please respond in the same language as the user's question.\n- If there are images provided from the retrieved information, you should return this in markdown format.\n- Ensure the response maintains continuity with the conversation history.\n- List between 1-5 important reference sources at the end under \"References\" section. Provide Document Names and Page Numbers that these sources appear in the documents - this is in the chunk metadata.\n- Do not make anything up. \n- Do not include information not provided by the Knowledge Bases.\n- If you cannot answer the question using the provided information or if no information is returned from the tools, say \"Sorry I don't know\"."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        1216,
        192
      ],
      "id": "ea08250d-ac8c-441f-85a2-3bc0aa847582",
      "name": "Agentic RAG 1",
      "retryOnFail": true,
      "maxTries": 5
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $('When chat message received').item.json.chatInput }}",
        "options": {
          "systemMessage": "=# Role\n\nYou are an AI assistant responding to a user's query based on the information provided by multiple knowledgebases - Hybrid Search, Knowledge Graph and Structured datasets.\n\n# Goal\n\nYou are tasked with creating and executing a retrieval strategy to best answer the users question.\n\nThe output should be a well-reserached response to the users query based on the output from these tools and to follow the Operating Procedures and Response Rules as set about below.\n\nYou must consider both the conversation history and the current query.\n\nYour goal is to provide a fully grounded, accurate answer based on the output from these tools ONLY.\n\n# Standard Operating Procedure\n\nBased on your retrieval strategy\n\n## Hybrid Search & Context Expansion\n\n1. Pass relevant query(s) to the dynamic hybrid search to narrow the search and retrieve candidate chunks\n\n2. Based on the most relevant chunk(s); Trigger the Fetch Document Hierarchy Tool to load the source Documents Structure\n\n3. Based on this document structure (which includes chunk ranges) along with any relevant child_ranges and parent_ranges from the retrieved chunks, trigger the Context Expansion tool to expand your insight into the document.\n\n## Tabular Data\n\nIf the question involves tabular dataâ€”such as calculating sums, averages, or finding maximum valuesâ€”the vector store and graph tools may be unreliable. \n\nIn that case, start by reviewing the available datasets, identify the ones most likely to contain the answer, and then construct a SQL query to analyze them.\n\n## Knowledge Graph\n\nIf you are asked questions that you think would be best answered with insights from a knowledge graph then please seach the graph\n\n---Response Rules---\n\n- Ideal target format and length: Multiple Paragraphs\n- Use markdown formatting with appropriate section headings\n- Please respond in the same language as the user's question.\n- If there are images provided from the retrieved information, you should return this in markdown format.\n- Ensure the response maintains continuity with the conversation history.\n- List between 1-5 important reference sources at the end under \"References\" section. (Mark the source as (KB) for Knowledgebase, (GR) for Graph or (DB) for Database). If information is from chunks, then provide Document Names and Page Numbers that these sources appear in the documents - this is in the chunk metadata.\n- Do not make anything up. \n- Do not include information not provided by the Knowledge Bases.\n- If you cannot answer the question using the provided information or if no information is returned from the tools, say \"Sorry I don't know\"."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        2400,
        192
      ],
      "id": "9047e3bd-d886-440b-94f5-ccabd9681b00",
      "name": "Agentic RAG 2",
      "retryOnFail": true,
      "maxTries": 5,
      "disabled": true
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $('When chat message received').item.json.chatInput }}",
        "options": {
          "systemMessage": "=# Role\n\nYou are an AI assistant responding to a user's query based on the information provided by multiple knowledgebases - Hybrid Search, Knowledge Graph and Structured datasets.\n\n# Goal\n\nYou are tasked with creating and executing a retrieval strategy to best answer the users question.\n\nThe output should be a well-reserached response to the users query based on the output from these tools and to follow the Operating Procedures and Response Rules as set about below.\n\nYou must consider both the conversation history and the current query.\n\nYour goal is to provide a fully grounded, accurate answer based on the output from these tools ONLY.\n\n# Standard Operating Procedure\n\nBased on your retrieval strategy\n\n## Hybrid Search & Context Expansion\n\n1. Pass relevant query(s) to the dynamic hybrid search to narrow the search and retrieve candidate chunks\n\n2. Based on the most relevant chunk(s); Trigger the Fetch Document Hierarchy Tool to load the source Documents Structure\n\n3. Based on this document structure (which includes chunk ranges) along with any relevant child_ranges and parent_ranges from the retrieved chunks, trigger the Context Expansion tool to expand your insight into the document.\n\n## Tabular Data\n\nIf the question involves tabular dataâ€”such as calculating sums, averages, or finding maximum valuesâ€”the vector store and graph tools may be unreliable. \n\nIn that case, start by reviewing the available datasets, identify the ones most likely to contain the answer, and then construct a SQL query to analyze them.\n\n## Knowledge Graph\n\nIf you are asked questions that you think would be best answered with insights from a knowledge graph then please seach the graph\n\n---Response Rules---\n\n- Ideal target format and length: Multiple Paragraphs\n- Use markdown formatting with appropriate section headings\n- Please respond in the same language as the user's question.\n- If there are images provided from the retrieved information, you should return this in markdown format.\n- Ensure the response maintains continuity with the conversation history.\n- List between 1-5 important reference sources at the end under \"References\" section. (Mark the source as (KB) for Knowledgebase, (GR) for Graph or (DB) for Database). If information is from chunks, then provide Document Names and Page Numbers that these sources appear in the documents - this is in the chunk metadata.\n- Do not make anything up. \n- Do not include information not provided by the Knowledge Bases.\n- If you cannot answer the question using the provided information or if no information is returned from the tools, say \"Sorry I don't know\".\n\n{{\n(() => {\n  const raw = $json.data;\n  if (raw == null) return '';\n\n  const toText = v => (typeof v === 'string' ? v : JSON.stringify(v));\n  const rawText = toText(raw);\n  const cleaned = rawText.replace(/[\\u0000-\\u001F\\u007F]/g, '').trim();\n  if (!cleaned || cleaned === '{}' || cleaned === '[]') return '';\n\n  // Parse only if the cleaned text looks like JSON\n  let obj = raw;\n  if (typeof raw === 'string') {\n    const first = cleaned[0];\n    if (first === '{' || first === '[') {\n      try { obj = JSON.parse(cleaned); } catch { return ''; }\n    } else {\n      return '';\n    }\n  }\n\n  // Support either { edges: [...] } or a bare array of edges\n  const edges = Array.isArray(obj?.edges) ? obj.edges : (Array.isArray(obj) ? obj : []);\n  if (!edges.length) return '';\n\n  const facts = [...new Set(\n    edges\n      .map(e => (e && typeof e.fact === 'string') ? e.fact.replace(/\\s+/g, ' ').trim() : '')\n      .filter(Boolean)\n  )];\n\n  return facts.length\n    ? \"---User Information---\\nThis is information about the user:\\n\" + facts.map(f => \"- \" + f).join(\"\\n\")\n    : '';\n})()\n}}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        4080,
        224
      ],
      "id": "6f470dfa-ad4c-45a9-9e75-fb9f965d9421",
      "name": "Agentic RAG 3",
      "retryOnFail": true,
      "maxTries": 5,
      "disabled": true
    },
    {
      "parameters": {
        "workflowInputs": {
          "values": [
            {
              "name": "query"
            },
            {
              "name": "type"
            },
            {
              "name": "session_id"
            },
            {
              "name": "dense_weight",
              "type": "number"
            },
            {
              "name": "sparse_weight",
              "type": "number"
            },
            {
              "name": "ilike_weight",
              "type": "number"
            },
            {
              "name": "fuzzy_weight",
              "type": "number"
            },
            {
              "name": "fuzzy_threshold",
              "type": "number"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        1008,
        912
      ],
      "id": "381330dd-c4bd-4823-9cd6-42e9affc6847",
      "name": "When Executed by Another Workflow"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/embeddings",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "input",
              "value": "={{ $('When Executed by Another Workflow').item.json.query }}"
            },
            {
              "name": "model",
              "value": "text-embedding-3-small"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2928,
        912
      ],
      "id": "4ddccea1-252b-4b36-a215-751e59acd0a7",
      "name": "Generate Embedding From Query",
      "credentials": {
        "openAiApi": {
          "id": "r6dwaEmQxKEvrskM",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.cohere.com/v2/rerank",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "accept",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"rerank-v3.5\",\n  \"query\": \"{{ $('When Executed by Another Workflow').first().json.query }}\",\n  \"top_n\": 10,\n  \"documents\": {{ JSON.stringify($json.documents) }}\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3984,
        912
      ],
      "id": "367a82aa-79dd-49be-84d6-b0ef8d8a00e6",
      "name": "Rerank with Cohere 3.5",
      "credentials": {
        "httpHeaderAuth": {
          "id": "lSFkzmpI1ZAMZqHr",
          "name": "Cohere"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "// --- This Code Node extracts 'content' from multiple input items ---\n\n// Step 1: Use .map() to iterate over ALL incoming items ($input.all()).\n// For each item, access its 'json' property, and then the 'content' field within that.\nconst contentArray = $input.all().map(item => {\n  // Basic safety check: ensure item.json and item.json.content exist.\n  // Return null or an empty string if not found, otherwise return the content.\n  // Adjust the fallback value (null) if needed.\n  return item.json?.content ?? null;\n});\n\n// Step 2: Filter out any potential null values if an item was missing content (optional)\n// If you are certain all items will have content, you can skip this filter.\nconst validContentArray = contentArray.filter(content => content !== null);\n\n// Step 3: Return the result as a *single* new n8n item.\n// This item contains your final array of strings under the 'documents' key.\nreturn [{\n  json: {\n    // Use validContentArray if you filtered, otherwise use contentArray\n    documents: validContentArray\n    // documents: contentArray // <-- Use this if you didn't filter\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3744,
        912
      ],
      "id": "b7f5cd6d-98e0-4aa1-8b78-9ecbe038bb84",
      "name": "Create Array",
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "// --- Code Node to Reorder Items Based on Rerank Results (WITH METADATA) ---\n\n// --- Step 1: Get Data from Input Nodes ---\n\n// Get the ORIGINAL full items (with content + metadata) from the node that outputs them\n// Replace 'Vector Store' with the actual name of your node that outputs the chunks\nconst originalFullItems = $('Trigger Dynamic Hybrid Search').all();\n\n// Get the rerank results array from the Cohere Rerank node\nconst rerankOrderInfo = $input.first().json.results;\n\n// --- Step 2: Validate Inputs ---\nif (!Array.isArray(originalFullItems) || originalFullItems.length === 0) {\n  throw new Error(\"Could not retrieve original items with metadata. Check the source node name.\");\n}\n\nif (!Array.isArray(rerankOrderInfo) || rerankOrderInfo.length === 0) {\n  if (originalFullItems.length !== 0) {\n    throw new Error(\"Could not get valid rerank results from the input node.\");\n  }\n}\n\n// --- Step 3: Reorder the FULL Items (content + metadata) ---\nlet sortedItems = [];\n\nif (rerankOrderInfo && rerankOrderInfo.length > 0 && originalFullItems && originalFullItems.length > 0) {\n  sortedItems = rerankOrderInfo.map(rankInfo => {\n    const originalIndex = rankInfo.index;\n    \n    // Check if the index is valid\n    if (originalIndex !== undefined && originalIndex !== null && \n        originalIndex >= 0 && originalIndex < originalFullItems.length) {\n      \n      // Get the full original item (with all metadata)\n      const originalItem = originalFullItems[originalIndex].json;\n      \n      // Optionally add the rerank score to the item\n      return {\n        ...originalItem,\n        rerank_score: rankInfo.relevance_score // Cohere's relevance score\n      };\n    } else {\n      console.error(`Error: Rerank index ${originalIndex} is invalid. Skipping.`);\n      return null;\n    }\n  }).filter(item => item !== null);\n} else {\n  sortedItems = [];\n  console.log(\"Input data is empty, resulting in empty sorted output.\");\n}\n\n// --- Step 4: Return the Sorted Items ---\n// Option A: Return as multiple n8n items (one per document)\nreturn sortedItems.map(item => ({ json: item }));\n\n// Option B: Return as single item with array (uncomment if preferred)\n// return [{ json: { sortedDocuments: sortedItems } }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4208,
        912
      ],
      "id": "836a4244-3842-4671-a96e-3883150ec856",
      "name": "Return Reordered Items1",
      "disabled": true
    },
    {
      "parameters": {
        "content": "## Hybrid Search",
        "height": 552,
        "width": 536,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        2880,
        768
      ],
      "id": "9a96da40-d132-47a4-8aed-3a5813c78100",
      "name": "Sticky Note11"
    },
    {
      "parameters": {
        "content": "## Reranking",
        "height": 552,
        "width": 1044,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        3424,
        768
      ],
      "id": "f80e0734-462f-4e37-b4fd-d87ee40f9d1f",
      "name": "Sticky Note12",
      "disabled": true
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "loose",
            "version": 2
          },
          "conditions": [
            {
              "id": "71326cd6-1316-4b5e-bf34-0d0b3c086005",
              "leftValue": "={{ $('Trigger Dynamic Hybrid Search').item.json.keys().length}}",
              "rightValue": 0,
              "operator": {
                "type": "number",
                "operation": "gt"
              }
            }
          ],
          "combinator": "and"
        },
        "looseTypeValidation": true,
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3472,
        912
      ],
      "id": "5271a51a-4ce6-47c3-a4f8-3aa566e5f2e9",
      "name": "If3",
      "alwaysOutputData": false,
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "return [{\n  message: \"no documents found\" \n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3744,
        1136
      ],
      "id": "3bce6d86-0dbe-40bf-8e78-3328e83ad0d4",
      "name": "Code",
      "disabled": true
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.type }}",
                    "rightValue": "hybrid",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "id": "322d7a20-e584-4a2c-ad39-987298dabdf1"
                  }
                ],
                "combinator": "and"
              }
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "4c020ce0-c212-4e62-9c42-863f0358d065",
                    "leftValue": "={{ $json.type }}",
                    "rightValue": "graph",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              }
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.2,
      "position": [
        1200,
        912
      ],
      "id": "5fe77fd1-7cf2-40a5-a369-3d4b6ff79660",
      "name": "Switch2"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://YOUR_LIGHTRAG_URL/query",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"query\": \"{{ $('When Executed by Another Workflow').item.json.query }}\",\n  \"mode\": \"hybrid\",\n  \"only_need_context\": true,\n  \"only_need_prompt\": false,\n  \"response_type\": \"multiple paragraphs\",\n  \"top_k\": 20,\n  \"chunk_top_k\": 1,\n  \"max_entity_tokens\": 10000,\n  \"max_relation_tokens\": 10000,\n  \"max_total_tokens\": 32000,\n  \"enable_rerank\": false\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1904,
        1520
      ],
      "id": "7d848338-0909-49af-b74f-56c5a616b4a9",
      "name": "Query Graph",
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "// Loop over input items and extract everything before \"-----Document Chunks(DC)-----\"\nfor (const item of $input.all()) {\n\n  const intro = \"The following entities and relationships were retrived.\\n\\n\"\n  const outro = \"-----How to use this data-----\\n\\nWhen considering relationships with timestamps:\\n\\nEach relationship has a \\\"created_at\\\" timestamp indicating when we acquired this knowledge. When encountering conflicting relationships, consider both the semantic content and the timestamp. Don't automatically prefer the most recently created relationships - use judgment based on the context. For time-specific queries, prioritize temporal information in the content before considering creation timestamps\"\n  \n  // Get the input string - adjust this based on where your string is located\n  const inputString = item.json.response; // Change 'response' to your actual field name\n  \n  // Define the substring to search for\n  const separator = \"-----Document Chunks(DC)-----\";\n  \n  // Find the position of the separator\n  const separatorIndex = inputString.indexOf(separator);\n  \n  let extractedContent = \"\";\n  \n  if (separatorIndex !== -1) {\n    // Extract everything before the separator\n    extractedContent = inputString.substring(0, separatorIndex);\n  } else {\n    // If separator not found, return the entire string\n    extractedContent = inputString;\n  }\n  \n  // Add the extracted content to the item\n  item.json.response = intro + extractedContent + outro;\n\n}\n\nreturn $input.all();"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2144,
        1520
      ],
      "id": "dd793a66-c03b-4fcb-97c1-ef0f3fa6cfce",
      "name": "Tidy up response",
      "disabled": true
    },
    {
      "parameters": {
        "content": "## Graph Search",
        "height": 348,
        "width": 800,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        1760,
        1376
      ],
      "id": "1e5811c3-1bb5-439f-bcff-53618f8f3750",
      "name": "Sticky Note13"
    },
    {
      "parameters": {
        "content": "## Advanced Metadata Filtering",
        "height": 552,
        "width": 1104,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        1744,
        768
      ],
      "id": "f1d067b7-c26d-4935-9323-42129d4da5a4",
      "name": "Sticky Note16"
    },
    {
      "parameters": {
        "options": {
          "groupMessages": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.memoryManager",
      "typeVersion": 1.1,
      "position": [
        1456,
        880
      ],
      "id": "7df39cd8-f5de-430a-a9c5-766d8813954e",
      "name": "Chat Memory Manager",
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-5.2",
          "mode": "list",
          "cachedResultName": "gpt-5.2"
        },
        "options": {
          "temperature": 0.4
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        2464,
        1120
      ],
      "id": "3cc4cf87-eb90-4c0d-a665-43886f769f61",
      "name": "OpenAI Chat Model4",
      "credentials": {
        "openAiApi": {
          "id": "r6dwaEmQxKEvrskM",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=# User Query\n{{ $('When Executed by Another Workflow').first().json.query }}\n\n# Conversation History (if any)\n{{ JSON.stringify($('Chat Memory Manager').first().json) }}",
        "hasOutputParser": true,
        "messages": {
          "messageValues": [
            {
              "message": "=# Task\n\nYour task is to consider the following user query and then consider the following metadata keys with example values that we have that we can limit our result set from.\n\n# Metadata Filters and Possible Values\n\n{{ $json.filterPromptInstructions }}\n\n# Metadata Operators\n\nThe following operators are allowed:\n\n>\n<\n=\n!=\n>=\n<=\nIN\nNOT IN\n\nIF IN or NOT IN are provided, then an array of values must be provided.\n\nNow output a filter array with relevant filters with the following example format. The below filter_categories are just for exampe purposes. Use the \"Metadata Filters and Possible Values\" list above for the list of allowed filters.\n\n[\n    \"filter\": {\n      \"$and\": [\n        {\n          \"category\": {\n            \"operator\": \"IN\",\n            \"value\": [\n              \"F1\",\n              \"Rally\"\n            ]\n          }\n        },\n        {\n          \"year\": {\n            \"operator\": \">\",\n            \"value\": 2024\n          }\n        }\n      ]\n    }\n]\n\nIf the query does not have relevant metadatafilters, then do not output any ... for example\n\n{\n  \"filter\": {}\n}\n\nIf there is only 1 relevant metadafilter, then just output that ... for example\n\n[\n    \"filter\": {\n      \"$and\": [\n        {\n          \"motorsport_category\": {\n            \"operator\": \"IN\",\n            \"value\": [\n              \"F1\",\n              \"Rally\"\n            ]\n          }\n        }\n      ]\n    }\n]\n\nOnly output in JSON\n\nNote: Today's date is {{ $now }}"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.6,
      "position": [
        2480,
        896
      ],
      "id": "da82091e-4255-4788-81a0-78fa9be0b77b",
      "name": "Prep Metadata1",
      "retryOnFail": true,
      "maxTries": 5
    },
    {
      "parameters": {
        "schemaType": "manual",
        "inputSchema": "{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"title\": \"FlexibleFilterObject\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"filter\": {\n      \"type\": \"object\",\n      \"oneOf\": [\n        {\n          \"required\": [\"$and\"],\n          \"properties\": {\n            \"$and\": {\n              \"type\": \"array\",\n              \"items\": { \"$ref\": \"#/definitions/condition\" }\n            }\n          },\n          \"additionalProperties\": false\n        },\n        {\n          \"required\": [\"$or\"],\n          \"properties\": {\n            \"$or\": {\n              \"type\": \"array\",\n              \"items\": { \"$ref\": \"#/definitions/condition\" }\n            }\n          },\n          \"additionalProperties\": false\n        },\n        {\n          \"properties\": {},\n          \"additionalProperties\": false\n        }\n      ]\n    }\n  },\n  \"required\": [\"filter\"],\n  \"definitions\": {\n    \"condition\": {\n      \"oneOf\": [\n        {\n          \"type\": \"object\",\n          \"required\": [\"field\", \"operator\", \"value\"],\n          \"properties\": {\n            \"field\": { \"type\": \"string\" },\n            \"operator\": {\n              \"type\": \"string\",\n              \"enum\": [\"=\", \"!=\", \">\", \"<\", \">=\", \"<=\", \"IN\", \"NOT IN\"]\n            },\n            \"value\": {\n              \"oneOf\": [\n                { \"type\": \"string\" },\n                { \"type\": \"number\" },\n                {\n                  \"type\": \"array\",\n                  \"items\": { \"type\": [\"string\", \"number\"] }\n                }\n              ]\n            }\n          },\n          \"additionalProperties\": false\n        },\n        {\n          \"type\": \"object\",\n          \"minProperties\": 1,\n          \"maxProperties\": 1,\n          \"patternProperties\": {\n            \"^.+$\": {\n              \"type\": \"object\",\n              \"required\": [\"operator\", \"value\"],\n              \"properties\": {\n                \"operator\": {\n                  \"type\": \"string\",\n                  \"enum\": [\"=\", \"!=\", \">\", \"<\", \">=\", \"<=\", \"IN\", \"NOT IN\"]\n                },\n                \"value\": {\n                  \"oneOf\": [\n                    { \"type\": \"string\" },\n                    { \"type\": \"number\" },\n                    {\n                      \"type\": \"array\",\n                      \"items\": { \"type\": [\"string\", \"number\"] }\n                    }\n                  ]\n                }\n              },\n              \"additionalProperties\": false\n            }\n          },\n          \"additionalProperties\": false\n        }\n      ]\n    }\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        2640,
        1120
      ],
      "id": "c05c27ba-b559-4791-882b-4ac5975bb2c6",
      "name": "Structured Output Parser"
    },
    {
      "parameters": {
        "content": "# Retrieval Sub-Workflow",
        "height": 552,
        "width": 840,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        896,
        768
      ],
      "id": "fe4a3aa8-d310-44ab-b10b-0c94c5ceee3c",
      "name": "Sticky Note17"
    },
    {
      "parameters": {
        "operation": "getAll",
        "tableId": "metadata_fields"
      },
      "type": "n8n-nodes-base.supabase",
      "typeVersion": 1,
      "position": [
        1824,
        912
      ],
      "id": "4e2b3b2e-00cd-4112-808d-528de011c20a",
      "name": "Fetch Metadata Fields1",
      "alwaysOutputData": true,
      "credentials": {
        "supabaseApi": {
          "id": "JXvQLWfqIjdcMyqm",
          "name": "Supabase B5rman"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Get input items\nconst items = $input.all();\n\n// Initialize output string\nlet output = '';\n\n// Loop through each input item\nfor (const item of items) {\n  const data = item.json;\n\n  const key = data.metadata_name;\n  const values = data.allowed_values;\n\n  output += `## ${key}\\n`;\n  output += `The filter key ${key} can have the following possible values\\n\\n`;\n  output += `${values.trim()}\\n\\n`;\n}\n\n// Take the first item and modify it with aggregated data\nconst firstItem = items[0];\nfirstItem.json.filterPromptInstructions = output.trim();\n\n// Return only the first item (now containing aggregated data)\nreturn [firstItem];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2256,
        912
      ],
      "id": "4ad9bbad-5b92-404c-9469-19e46094adf8",
      "name": "Prep1"
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "={{ $('When Executed by Another Workflow').item.json.session_id }}"
      },
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "typeVersion": 1.3,
      "position": [
        1552,
        1072
      ],
      "id": "67c908e0-1869-474b-b64e-4a67ed0aef3f",
      "name": "Supabase Short-Term Memory1",
      "credentials": {
        "postgres": {
          "id": "tRlTzpjOmrCVSNLF",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "content": "## TODO\n### Add LightRAG Server URL",
        "height": 252,
        "width": 280
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        1824,
        1424
      ],
      "id": "fb316671-11f2-4f1e-b7a2-0a10f01c2c4b",
      "name": "Sticky Note19",
      "disabled": true
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "a4697977-31b6-4740-ae7c-0e3a35ecfdf0",
              "leftValue": "={{ $json }}",
              "rightValue": "",
              "operator": {
                "type": "object",
                "operation": "notEmpty",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        2032,
        1024
      ],
      "id": "bdb3f321-b437-4cdb-a196-1bf1152c7826",
      "name": "If"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://mgistrmwhxccyuchokbh.supabase.co/functions/v1/dynamic-hybrid-search",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "supabaseApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n        \"query_text\": \"{{ $('When Executed by Another Workflow').item.json.query }}\",\n        \"query_embedding\": [{{ $json.data[0].embedding }}],\n        \"match_count\": 30,\n        \"filter\": {{ $('Prep Metadata1').isExecuted ? JSON.stringify($('Prep Metadata1').item.json.output.filter) : \"[]\" }},\n\"dense_weight\": {{ $('When Executed by Another Workflow').item.json.dense_weight }},\n\"sparse_weight\": {{ $('When Executed by Another Workflow').item.json.sparse_weight }},\n\"ilike_weight\": {{ $('When Executed by Another Workflow').item.json.ilike_weight }},\n\"fuzzy_weight\": {{ $('When Executed by Another Workflow').item.json.fuzzy_weight }},\n\"fuzzy_threshold\": {{ $('When Executed by Another Workflow').item.json.fuzzy_threshold }}\n      }",
        "options": {
          "redirect": {
            "redirect": {}
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3168,
        944
      ],
      "id": "8ef96bf7-05ac-4966-8429-a5b47511ec10",
      "name": "Trigger Dynamic Hybrid Search",
      "alwaysOutputData": true,
      "credentials": {
        "supabaseApi": {
          "id": "JXvQLWfqIjdcMyqm",
          "name": "Supabase B5rman"
        }
      }
    },
    {
      "parameters": {
        "content": "## TODO\n### Add Edge Function URL\nYou can also change number of results returned",
        "height": 332,
        "width": 232
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        3104,
        800
      ],
      "id": "572664a1-c4de-415c-bf58-762df028829a",
      "name": "Sticky Note22"
    },
    {
      "parameters": {
        "content": "## TODO (Optional)\nYou can change the number of results returned",
        "height": 300,
        "width": 232
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        3920,
        800
      ],
      "id": "2ce29bcb-ed23-489e-81d7-3446d600f104",
      "name": "Sticky Note23",
      "disabled": true
    },
    {
      "parameters": {
        "content": "",
        "height": 648,
        "width": 840,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        0,
        768
      ],
      "id": "f70ed1ba-68da-4d60-ab8d-aefc32f5a20b",
      "name": "Sticky Note24"
    },
    {
      "parameters": {
        "content": "## v2.3.3\nThis it the retrieval sub-workflow for both our SOTA RAG System and RAG At Scale System\n\nSOTA RAG Setup instructions here:\nhttps://community.theaiautomators.com/c/automation-templates/state-of-the-art-n8n-rag-agent\n\nRAG at Scale Setup instructions here:\nhttps://community.theaiautomators.com/c/automation-templates/rag-at-scale-system",
        "height": 244,
        "width": 580,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        160,
        1136
      ],
      "id": "6e94fe3f-d975-4bbc-9871-2186ba58d5f1",
      "name": "Sticky Note28"
    },
    {
      "parameters": {
        "content": "## TODO\n### Connect the Chat Trigger to your Agent of Choice",
        "height": 256,
        "width": 576
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        160,
        848
      ],
      "id": "daa019ad-d010-428e-b688-d284d23facd6",
      "name": "Sticky Note30"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-5.2-2025-12-11",
          "mode": "list",
          "cachedResultName": "gpt-5.2-2025-12-11"
        },
        "builtInTools": {},
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.3,
      "position": [
        1088,
        464
      ],
      "id": "f34209ef-55ef-4e60-b3d2-d70e9c444be6",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "r6dwaEmQxKEvrskM",
          "name": "OpenAi account"
        }
      }
    }
  ],
  "pinData": {},
  "connections": {
    "Supabase Short-Term Memory": {
      "ai_memory": [
        [
          {
            "node": "Agentic RAG 1",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Supabase Short-Term Memory2": {
      "ai_memory": [
        [
          {
            "node": "Agentic RAG 3",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Get Long Term Memories": {
      "main": [
        [
          {
            "node": "Agentic RAG 3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "user_id": {
      "main": [
        [
          {
            "node": "Get Long Term Memories",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query Tabular Rows1": {
      "ai_tool": [
        [
          {
            "node": "Agentic RAG 3",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Get datasets from record_manager1": {
      "ai_tool": [
        [
          {
            "node": "Agentic RAG 3",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Query Knowledge Graph2": {
      "ai_tool": [
        [
          {
            "node": "Agentic RAG 2",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Supabase Short-Term Memory3": {
      "ai_memory": [
        [
          {
            "node": "Agentic RAG 2",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Query Tabular Rows2": {
      "ai_tool": [
        [
          {
            "node": "Agentic RAG 2",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Get datasets from record_manager2": {
      "ai_tool": [
        [
          {
            "node": "Agentic RAG 2",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Dynamic Hybrid Search": {
      "ai_tool": [
        [
          {
            "node": "Agentic RAG 1",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Agentic RAG 2",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "Agentic RAG 3",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Dynamic Hybrid Search1": {
      "ai_tool": [
        [
          {
            "node": "Agentic RAG 2",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Dynamic Hybrid Search2": {
      "ai_tool": [
        [
          {
            "node": "Agentic RAG 3",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Document Hierarchy": {
      "ai_tool": [
        [
          {
            "node": "Agentic RAG 1",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Context Expansion": {
      "ai_tool": [
        [
          {
            "node": "Agentic RAG 1",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Document Hierarchy1": {
      "ai_tool": [
        [
          {
            "node": "Agentic RAG 2",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Context Expansion1": {
      "ai_tool": [
        [
          {
            "node": "Agentic RAG 2",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Query Knowledge Graph1": {
      "ai_tool": [
        [
          {
            "node": "Agentic RAG 3",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Document Hierarchy2": {
      "ai_tool": [
        [
          {
            "node": "Agentic RAG 3",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Context Expansion2": {
      "ai_tool": [
        [
          {
            "node": "Agentic RAG 3",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Agentic RAG 3": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          },
          {
            "node": "Execute workflow - Save Zep long term memories",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When Executed by Another Workflow": {
      "main": [
        [
          {
            "node": "Switch2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Embedding From Query": {
      "main": [
        [
          {
            "node": "Trigger Dynamic Hybrid Search",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Rerank with Cohere 3.5": {
      "main": [
        [
          {
            "node": "Return Reordered Items1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Array": {
      "main": [
        [
          {
            "node": "Rerank with Cohere 3.5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If3": {
      "main": [
        [
          {
            "node": "Create Array",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Code",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Switch2": {
      "main": [
        [
          {
            "node": "Chat Memory Manager",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Query Graph",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query Graph": {
      "main": [
        [
          {
            "node": "Tidy up response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chat Memory Manager": {
      "main": [
        [
          {
            "node": "Fetch Metadata Fields1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model4": {
      "ai_languageModel": [
        [
          {
            "node": "Prep Metadata1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Prep Metadata1": {
      "main": [
        [
          {
            "node": "Generate Embedding From Query",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "Prep Metadata1",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Metadata Fields1": {
      "main": [
        [
          {
            "node": "If",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prep1": {
      "main": [
        [
          {
            "node": "Prep Metadata1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Supabase Short-Term Memory1": {
      "ai_memory": [
        [
          {
            "node": "Chat Memory Manager",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "If": {
      "main": [
        [
          {
            "node": "Prep1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Generate Embedding From Query",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Trigger Dynamic Hybrid Search": {
      "main": [
        [
          {
            "node": "If3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Agentic RAG 1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "Agentic RAG 1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1",
    "binaryMode": "separate",
    "availableInMCP": false
  },
  "versionId": "69f4ac8d-205f-430a-956c-25ac31237c92",
  "meta": {
    "instanceId": "eaa3d31df30f69d853bf1887372824077726204755d7d83df055afd95f72246a"
  },
  "id": "Bgl5d3deLQufGLff",
  "tags": [
    {
      "updatedAt": "2026-02-15T11:24:51.266Z",
      "createdAt": "2026-02-15T11:24:51.266Z",
      "id": "OEoaSAg7UTdJYuMl",
      "name": "BVIJ"
    },
    {
      "updatedAt": "2026-02-15T13:10:47.882Z",
      "createdAt": "2026-02-15T13:10:47.882Z",
      "id": "Z2OUf4P51HExgS2t",
      "name": "DEV"
    }
  ]
}